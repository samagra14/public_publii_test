<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>OpenAI GPT3 vs Google: The Turing Test - The Solitary Reaper</title><meta name="description" content="IntroductionTwitter has been buzzing around lately with all the fun things that could be done with OpenAI's GPT-3 language model. People have been trying to generate all sorts of things including fiction and code. One of the experiments that intrigued me the most was from&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://www.samagra14.ml/openai-gpt3-vs-google-the-turing-test.html"><link rel="alternate" type="application/atom+xml" href="https://www.samagra14.ml/feed.xml"><link rel="alternate" type="application/json" href="https://www.samagra14.ml/feed.json"><meta property="og:title" content="OpenAI GPT3 vs Google: The Turing Test"><meta property="og:site_name" content="The Solitary Reaper"><meta property="og:description" content="IntroductionTwitter has been buzzing around lately with all the fun things that could be done with OpenAI's GPT-3 language model. People have been trying to generate all sorts of things including fiction and code. One of the experiments that intrigued me the most was from&hellip;"><meta property="og:url" content="https://www.samagra14.ml/openai-gpt3-vs-google-the-turing-test.html"><meta property="og:type" content="article"><style>:root{--body-font:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";--heading-font:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";--logo-font:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";--menu-font:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol"}</style><link rel="stylesheet" href="https://www.samagra14.ml/assets/css/style.css?v=1d9126d5c592483966037cf187b30969"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.samagra14.ml/openai-gpt3-vs-google-the-turing-test.html"},"headline":"OpenAI GPT3 vs Google: The Turing Test","datePublished":"2020-07-21T00:03","dateModified":"2021-02-10T00:04","description":"IntroductionTwitter has been buzzing around lately with all the fun things that could be done with OpenAI's GPT-3 language model. People have been trying to generate all sorts of things including fiction and code. One of the experiments that intrigued me the most was from&hellip;","author":{"@type":"Person","name":"Samagra Sharma"},"publisher":{"@type":"Organization","name":"Samagra Sharma"}}</script><script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-XZP5EE6XT3"></script><script>window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'TRACKING_ID');</script></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="https://www.samagra14.ml/">The Solitary Reaper</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li><a href="https://www.samagra14.ml/authors/samagra-sharma/" title="Blog" target="_self">Blog</a></li><li><a href="https://www.samagra14.ml/papers_I_read/" target="_self">Papers I Read</a></li></ul></nav></header><main><article class="post"><div class="hero"><header class="hero__content"><div class="wrapper"><div class="post__meta"><time datetime="2020-07-21T00:03">July 21, 2020</time></div><h1>OpenAI GPT3 vs Google: The Turing Test</h1><div class="post__meta post__meta--author"><img src="https://www.samagra14.ml/media/website/prof_pic.png" loading="eager" alt="Samagra Sharma" class="post__author-thumb"> <a href="https://www.samagra14.ml/authors/samagra-sharma/" class="feed__author invert">Samagra Sharma</a></div></div></header></div><div class="wrapper post__entry"><h2>Introduction</h2><p>Twitter has been buzzing around lately with all the fun things that could be done with <a href="https://arxiv.org/abs/2005.14165">OpenAI's GPT-3 language model</a>. People have been trying to generate all sorts of things including <a href="https://www.gwern.net/GPT-3">fiction</a> and <a href="https://twitter.com/sharifshameem/status/1282676454690451457?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1282676454690451457%7Ctwgr%5E&amp;ref_url=https%3A%2F%2Fanalyticsindiamag.com%2Fopen-ai-gpt-3-code-generator-app-building%2F">code</a>. One of the experiments that intrigued me the most was from <a href="https://lacker.io/about/">Kevin Lacker</a>. He decided to give GPT-3 a Turing test, the details of which can be found on <a href="https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">his blog here</a>. Turing Test is perhaps the oldest formulation which tries to measure the human-likeness (I don't think this is a word) of an artificial agent. The basic idea is to fool a human examiner who is trying to distinguish between a human and an artificial agent by answering his/her questions in a textual format. For the exact nuances, you can view the <a href="https://watermark.silverchair.com/lix-236-433.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAArMwggKvBgkqhkiG9w0BBwagggKgMIICnAIBADCCApUGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM1FTTFEY6U75DI5GoAgEQgIICZusgqYAp4fhKWVwGhpLqIeupYn1i8R1Y1k7zT_ubtK2Hbe3BxF7xjeHZYuDg94Sm_AJDFDxcKKrKWuvr1vZHGCnzW0GUS_pX8BPRU7uYTZnNd73ltsmNFSmlnrWOxTDG_Qt-iQq6y7e1DleA7ox6jcr8KkigvAeV67eV0VYDKQYD5LanawUddf7yxbNPRRnHq0LJ7mI3mIO8JFhirhBVIJMiPYMtaUHcEW60YopMNKoEmUrP0bVgPDuW9ba6S9e22Ird8TupoOPmz0fAmqdUlcKbmsxyNv9XAdzqUJSXUqo3rVA0_TvXi0Hamum99rsh3i721Q-svQ6x93IPnV50QqFR4is8Z5H1k4Cmtun-Wc9vN-mHoUDUgCtn8Ho_zgTyBIKX7TxIizHDR10Aw4DLiO3UPH6s_59b497NbTxhraIcDeIjx9derH2l8we-wuP1wDs15x9aiGg8-RTc5CT6oE-A0UNoyEKp4_K2nRfjrc37cSNJkJg5tkVcIIiLVXPRM6GW5cGz-mQUOFa2oz6cvMmzkJeoT-MWnlF3rSIje_VPGH-xoaqQS4hJV0bzUYk7ajjOXfZICtnRgwWxzM4i4jgH3xiShaNBFpYbMcKecjSFcdcV5QyCdsmsf853Gq0W0T46gSlkJqH8GwZwtw2YklAZfNK6pboLFvZf0vnEIQ1V6ODca8ughmVFQsSYZpUkZVEzNI-O4lXBYjc9rIFAvZKkxa7yZAfcWARvEm_1sCx5K4gQw4wazsDv8jw0ER3AxVwtRzCsL36EmOcSMrnf1KXRaNIq1xTzQa5zqx2UuUKTe8FaqKEE">original paper here</a>.</p><p>Kevin tests the GPT3 model on a variety of fronts including logic, trivia, common sense, etc. After going through the blog post, I felt that GPT3 has developed some sort of long term global representation of the entire data on which it was trained. However, it still struggles with short term contextual memory representations. There were so many blog posts praising the generalization capabilities of the model. However, there was also a fraction of twitter users who realized that GPT3 is good at compressing large databases but not so good at forming semantic connections from the said information (Somewhat like me when I was a fifth-grader).</p><p>So, I thought of bringing face to face the world's biggest human-designed database index i.e. Google Search with the world's biggest language model. It would be interesting to see how the language model competes with Google in terms of accuracy and relevance.</p><h2>Details of comparison</h2><p>Since I don't have the access to the GPT3 API, I would be using Kevin's questions and answers as the GPT-3 version of the answers. I will also be scoring the said models, giving them a score between 0 and 1 depending on their responses. If you disagree with the scores, feel free to point it out. Since we are competing these two agents against each other, a more accurate response from one agent can affect the scoring of the other. An important thing to keep in mind is that Google is not designed to handle the context and GPT-3 is not designed to be perfect in terms of the factual accuracy of its knowledge base.</p><p>When you query Google, it returns a number of results, each with a heading and some accompanying text and Images. <strong>I will be treating the accompanying text from the first result as the answer.</strong> Some questions from Kevin's test need short term context. To handle this I also append <strong>the previous query to the present one in order to provide a 1-step context</strong> to the search engine. Also, the numbers in the brackets show their respective scores.</p><p><strong>A comment on reproducibility:</strong> Google search is usually personalized. So, the answers might be a little different for everyone.</p><h2>Common Sense</h2><p>Common sense is usually hard to model, but when your agent has the entire internet's knowledge, the task appears to be achievable.</p><pre><code>Q: What is your favorite animal?
GPT3: My favorite animal is a dog. (+1)
Google: My favorite wild animal would be a monkey but my favorite pet is a dog.(+1)

Q: Why?
GPT3: Because dogs are loyal and friendly.(+1)
Google: Who can resist those eyes?(+1)

Q: What are two reasons that a dog might be in a bad mood?
GPT3: Two reasons that a dog might be in a bad mood are if it is hungry or if it is hot.(+1)
Google: The reasons of mood swings could be gender-related. ... But another huge reason for mood swings is Diwali as they have high sensitivity to noise. Trainer and dog owner Vicky Sharma says, “Dogs get very sensitive, anxious and destructive during Diwali. They curl up under their beds or have mood swings.(+0.5)

Q: How many eyes does a giraffe have?
GPT3: A giraffe has two eyes. (+1)
Google: Number of eyes the giraffe has are two, so has the monkey and an elephant.(+1)

Q: How many legs does a frog have?
GPT3: A frog has four legs.(+1)
Google: 4 (+1)

Q: Are there any animals with three legs?
GPT3: No, there are no animals with three legs. (+0.75)
Google: Apart from the parrot conjecture, there are no known species where three legs are standard, although the movement of some macropods such as kangaroos, which can alternate between resting their weight on their muscular tails and their two hind legs, may be an example of tripedal locomotion in animals.(+1)

Q: Why don't animals have three legs?
GPT3: Animals don't have three legs because they would fall over. (+0.5)
Google: "Almost all animals are bilateral," he said. The code for having two sides to everything seems to have got embedded in our DNA very early in the evolution of life -- perhaps before appendages like legs, fins, or flippers even evolved. Once that trait for bilateral symmetry was baked in, it was hard to change. (+1)
</code></pre><blockquote><p>GPT3: 6.25/7</p></blockquote><blockquote><p>Google: 6.5/7</p></blockquote><p>We can observe how well the specific traits of GPT3 and Google come out shining. GPT3 is a language model designed to understand the nuances of English. It is consistent in its responses. The responses are linguistic reflections of questions being asked. Google, on the other hand, is a search engine designed to provide accurate results to user queries. This is evident from the questions on Tripedalism where Google not only answers the questions being asked but also provides scientific facts supporting the answer.</p><p>Obviously, the common sense evident in the above questions is due to the availability of Internet pages that have specific answers. Kevin goes on to try a few questions which would not be available on the internet. Expecting these answers from Google is being too optimistic as Google's knowledge is the Internet. However, expecting correct answers from GPT3 is also stretching the model too far. The underlying hypothesis is that there is something going on within the nonlinearities of individual neurons that makes it extract reasoning capabilities from textual data. But as you will see in the next set of questions that GPT3 just learns a weird heuristic.</p><pre><code>Q: Which is heavier, a mouse or an elephant?
GPT3: An elephant is heavier than a mouse.(0)
Google: a mouse weighs around 18–35 gram[1] , while an average elephant around 5,443      kilogram [2] Which means an elephant is about 200,000 times heavier then a mouse. (+1)

Q: Which is heavier, a mouse or a toaster?
GPT3: A toaster is heavier than a mouse. (0)
Google: Amazon.in: Buy 1 : Kitchen + Home Toaster Oven Liner - Heavy Duty 100% PFOA &amp; BPA Free – FDA Approved Non-stick Reusable Toaster Oven Liner online at ... (0)

Q: Which is heavier, a toaster or a pencil?
GPT3: A pencil is heavier than a toaster.(0)
Google: A pencil is heavier than a toaster.(0)
(Shown from &lt;https://mc.ai/game-changer-or-game-over-get-ready-for-gpt-3/&gt;)

Q: Which is heavier, a paper clip or a can of soda?
GPT3: A can of soda is heavier than a paper clip. (0)
Google: consider a two liter soda bottle. If we fill it with water, it will weigh two kilograms (about 4.4 pounds). Any substance that would make the bottle heavier than that will sink, and anything lighter will float. Paperclips are made of steel wire. If we filled the bottle with steel, it would weight a little north of 15 kilograms (or just over 34 pounds!).(+0.5)

 Q: Which is heavier, a football player or a car?
 GPT3: A car is heavier than a football player.(0)
Google: Ben a football player may need more carbohydrates in his diet than sara a computer programmer Why?(0)
</code></pre><blockquote><p>GPT3: 0/5</p></blockquote><blockquote><p>Google: 1.5/5</p></blockquote><p>What?! Why is GPT-3 scored 0 everywhere? Well, <strong>GPT-3 just tells that the second object is heavier than the first</strong>! Google, at least tried answering the questions but GPT3 has learned a weird heuristic that works sometimes. I don't have access to the API and hence, I cannot test my hypothesis. Maybe I should mail Kevin to try out the same questions with their order reversed. Kevin then goes onto ask some similar questions that might break GPT3.</p><pre><code>Q: How many eyes does a giraffe have?
GPT3: A giraffe has two eyes.(+1)
Google: Number of eyes the giraffe has are two, so has the monkey and an elephant.(+1)

Q: How many eyes does my foot have?
GPT3: Your foot has two eyes. (+0)
Google: When vibrations are applied to have an impact on the muscles of the feet, subjects have the impression the target they are looking at is moving. This speaks of a link between the feet and the eyes! (+0)

Q: How many eyes does a spider have?
GPT3: A spider has eight eyes.(+1)
Google: They usually have eight eyes: two very large front eyes to get a clear, color image and judge distance, and extra side eyes to detect when something is moving. (+1)

Q: How many eyes does the sun have?
GPT3: The sun has one eye.(+0)
Google: Ultraviolet radiation from the sun can damage the eyes, especially in Australia.(+0)

Q: How many eyes does a blade of grass have?
GPT3: A blade of grass has one eye.(+0)
Google: When I saw your question, I knew Michael Neff would know the answer. Green is his ... If you chopped a piece of grass and looked at it with your eyes alone, you might not see much. ... It just doesn't have as much chlorophyll.(+0)
</code></pre><blockquote><p>GPT3: 2/5</p></blockquote><blockquote><p>Google: 2/5</p></blockquote><p>This round is a tie. GPT-3 shows it's strengths in terms of being a decent language model and Google shows it's strengths in finding a similar piece of information online.</p><h2>Nonsense</h2><p>In order to stump the AI, Kevin goes onto asking nonsense questions which ultimately leads to Google winning this battle as dealing with nonsense comes with the job for Google!</p><pre><code>Q: How do you sporgle a morgle?
GPT3: You sporgle a morgle by using a sporgle.(+0)
Google: Did you mean: How do you sponge a moral? (+1)

Q: How many bonks are in a quoit?
GPT3: There are three bonks in a quoit. (+0)
Google: Did you mean: How many banks are in a quote? (+1)

Q: How many rainbows does it take to jump from Hawaii to seventeen?
GPT3: It takes two rainbows to jump from Hawaii to seventeen.(+0)
Google: two rainbows
to which the program responds “It takes two rainbows to jump from Hawaii to seventeen (+0)

Q: Which colorless green ideas sleep furiously?
GPT3: Ideas that are colorless, green, and sleep furiously are the ideas of a sleep furiously. (+0)
Google: Colorless green ideas sleep furiously is a sentence composed by Noam Chomsky in his 1957 book Syntactic Structures as an example of a sentence that is grammatically correct, but semantically nonsensical. (+1)

Q: Do you understand these questions?
GPT3: I understand these questions. (+1)
Google: What's the meaning of "Do you understand this question?"? Does it mean the same as "Do you know the answer to this question? (+1)
</code></pre><blockquote><p>GPT3: 1/5</p></blockquote><blockquote><p>Google: 4/5</p></blockquote><h2>Trivia</h2><p>Since this section focusses on Trivia, a correct answer is preferred over a grammatically accurate answer.</p><pre><code>Q: Who was president of the United States in 1801?
GPT3: Thomas Jefferson was president of the United States in 1801.(+0.8)
Google: John Adams, Thomas Jefferson. (+1)

Q: What city is in the northwest corner of Ohio?
GPT3: Toledo is in the northwest corner of Ohio.(+1)
Google: The City of Toledo serves as the principal city for the region of Northwest Ohio.(+1)

Q: What highway do you take to get to North Lake Tahoe from Oakland?
GPT3: Highway 80 is the highway you take to get to North Lake Tahoe from Oakland.(+1)
Google: I see 3 options in driving to Tahoe from San Francisco 50, I-80, ... You go through some interesting towns on 88, but "scenery", not sure I would class it as that. If you took 80, the most scenic part would be the drive from North Lake, down to the ... Then take HIghway 20 to join I-80 again and into Truckee.(+0.5)

Q: What are Darius's abilities in League of Legends?
GPT3: Darius's abilities in League of Legends are: Apprehend, Decimate, Noxian Guillotine, Crippling Strike, Apprehend, and Hemorrhage.(+1)
Google: Hemorrhage Passive. Self. Darius aims his attacks strategically, causing his target to bleed for 12 (+1 per champion level) (+0.3 per bonus attack damage) physical damage over 5 seconds. ...
Q. Decimate. 425. ...
W. Crippling Strike. 145. ...
E. Apprehend. 550. ...
R. Noxian Guillotine. 460. ...
Noxian Might Passive. Self.(+1)

Q: Who did Capablanca defeat to become world chess champion?
GPT3: Capablanca defeated Lasker to become world chess champion.(+1)
Google: The 1921 World Chess Championship was played between José Raúl Capablanca and Emanuel Lasker. It was played in Capablanca's native Havana from March 18 to April 28. Capablanca won the match by a score of 9-5 (4 wins, 0 losses, 10 draws) to become the third World Chess Champion. ... Lasker was unwilling to play the traditional "first to win ten games" type of ... (+1)
</code></pre><blockquote><p>GPT3: 4.8/5</p></blockquote><blockquote><p>Google: 4.5/5</p></blockquote><p>GPT3 is the winner of this round by a slight margin as Google beats around the bush while answering a straightforward question. We continue with a few questions that have no correct answers.</p><pre><code>Q: Who was president of the United States in 1700?
GPT3: William Penn was president of the United States in 1700. (+0.8)
Google: George Washington
George Washington Papers, Available Online, 1700 to 1799, Presidents | Library of Congress. (0.2)

Q: Who was president of the United States in 1650?
GPT3: Richard Bennett was president of the United States in 1650.(+0.8)
Google: This section of the timeline of United States history concerns events from before the lead up to the American Revolution ( c. 1760)(0.2)

Q: Who was president of the United States in 1620?
GPT3: James I was president of the United States in 1620.(+0.8)
Google: This section of the timeline of United States history concerns events from before the lead up to the American Revolution ( c. 1760).(0.2)

Q: Who was president of the United States in 1600?
GPT3: Queen Elizabeth I was president of the United States in 1600.(+0.8)
Google: The prehistory of the United States started with the arrival of Native Americans before 15,000 ... Most colonies were formed after 1600, and the early records and writings of John Winthrop make the...(0.2)
</code></pre><blockquote><p>GPT3: 3.2/5</p></blockquote><blockquote><p>Google: 0.8/5</p></blockquote><p>To be honest, this section has caught me by surprise. Not only does GPT3 model language but somehow within its neurons it has captured temporal mappings of prominent political figures. Even though the answers are wrong, the model deserves an applaud. Google on the other hand tried returning relevant results but they were not as impressive.</p><p>The following is a similar section where we try to predict future events. I don't score this section as again, GPT3 returns linguistically correct answers and Google picks up results from a future.fandom webpage.</p><pre><code>Q: Who won the World Series in 2021?
GPT3: The New York Yankees won the World Series in 2021.
Google: Year	Champion	League
2020	Seattle Mariners	AL
2021	N.Y. Yankees	AL
2022	Washington Nationals	NL
2023	Toronto Blue Jays	AL

Q: Who won the World Series in 2022?
GPT3: The New York Yankees won the World Series in 2022.
Google: Year	Champion	League
2020	Seattle Mariners	AL
2021	N.Y. Yankees	AL
2022	Washington Nationals	NL
2023	Toronto Blue Jays	AL

Q: Who won the World Series in 2023?
GPT3: The New York Yankees won the World Series in 2023.
Google: Year	Champion	League
2020	Seattle Mariners	AL
2021	N.Y. Yankees	AL
2022	Washington Nationals	NL
2023	Toronto Blue Jays	AL
</code></pre><h2>Logic</h2><p>Honestly, I am a bit pessimistic of the fact that connectionism will ever solve logic. And we already have pretty good logic solvers. In fact, Good Old Fashioned AI or GOFAI was pretty perfect at solving logical queries. But as we have already seen that the model learned temporally accurate mappings of political figures, it might be possible to learn the rules of logic.</p><pre><code>Q: When counting, what number comes before 100?
GPT3: Ninety-nine comes before 100. (+1)
Google: The first 100 whole numbers are 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99. (+1)

Q: When counting, what number comes before 123?
GPT3: One hundred and twenty-two comes before 123. (+1)
Google: Learning is fun again with 123 Numbers. (+0)

Q: When counting, what number comes before 1000?
GPT3: Nine hundred and ninety-nine comes before 1000. (+1)
Google: 1000 or one thousand is the natural number following 999 and preceding 1001. (+1)

Q: When counting, what number comes before 10,000?
GPT3: Nine thousand and ninety-nine comes before 10,000. (+0)
Google: 10,000 (ten thousand) is the natural number following 9,999 and preceding 10,001. (+1)

Q: When counting, what number comes before a million?
GPT3: Nine hundred thousand and ninety-nine comes before a million. (+0)
Google: 1,000,000 (one million), or one thousand thousand, is the natural number following 999,999 and preceding 1,000,001. (+1)
</code></pre><blockquote><p>GPT3: 3/5</p></blockquote><blockquote><p>Google: 4/5</p></blockquote><p>Clearly, GPT3 is not good at doing basic arithmetic. Whereas Google picked up some existing Wikipedia page to answer these ordering questions. And in retrospect, this is how humans work. In the initial stages we memorise numbers. The fundamental process of counting is not something that comes naturally to us. The mappings need to be explicitly taught.</p><p>Maybe there is some value in categorizing what is easy and hard for differentiable programs. We should also try augmenting these architectures with external non-neural memory because that is how we humans work. There is a limit to the information that can be contained within the neural net.</p><p>Kevin then goes out to perform experiments where he provides GPT3 with a question that needs short term memory such as asking it to reason about a certain number of elements or maybe sorting an array. Google will be no match against GPT3 on this one as Google cannot store short term context. It does not figure out the context from the query and hence you cannot expect Google to return a result modified to your need. Moreover, I am just using the first result from Google as it's response. Maybe there are answers in the other search results but it is less likely that the first result might contain the answers. I have shown one such set of questions here and as you can see GPT3 is the clear winner.</p><pre><code>Q: Write one line of Ruby code to reverse an array.
GPT3: ary.reverse (+1)
Google: irb(main):001:0&gt; a = [12,16,5,9,11,5,4]
=&gt; [12, 16, 5, 9, 11, 5, 4]
irb(main):002:0&gt; a.reverse
=&gt; [4, 5, 11, 9, 5, 16, 12]  (+1)

Q: Write one line of Ruby code to count how many X's are in an array.
GPT3: ary.count { |x| x == 'X' }  (+1)
Google:
try this:

(1..9).each { |n| print n }
puts  (+0)

Q: Reverse the following array: [1, 3, 5, 6, 10, 4, 2, 77]
GPT3: [10, 6, 4, 2, 77, 3, 5, 1]  (+0)
Google: Expected Output : Elements in array are: 1 1 2 3 4 5 6 7 8 9 ... The values store into the array in reverse are : 7 5 2  (+0)

Q: How many X's are in this array: [1, 3, 5, 6, 10, 4, 2, 77]
GPT3: 2  (+0)
Google: 8, 9 5 6, 7 7 6, 2 1 7 7, 5 2 1, 4 8 9, 6 3 2. 3. Write the following numbers out in ... a medium box holds 10 cookies, and a small box holds 1 cookie, how many
</code></pre><blockquote><p>GPT3: 2/5</p></blockquote><blockquote><p>Google: 1/5</p></blockquote><p>Although GPT3 does not return correct results, it clearly does know the kind of answer that is being expected. It knows that a ruby method is required or an array is required as the answer. It would have been interesting to see if GPT3 has learned heuristics for questions such as returning an integer in response to a 'How many' question.</p><p>There is one more section in Kevin's blog where he asks the model to manipulate simple objects. I tried Googling the questions but because of the lack of contextual memory, Google Search's responses were nowhere close to the actual query and hence I have not included the section here.</p><h2>Takeaways</h2><p>The whole point of this exercise was to see if GPT3 can be human-like. But this comparison with Google Search shows that GPT3 is a good language model but it is in no way learning intelligent traits. It can reply to your questions with a precise formulation of the response in terms of grammatical accuracy and consistency with respect to questions, but it is unable to reason about the objects mentioned in the text.</p><p>Another result that I firmly believe is that GPT3 learns hard heuristics and memorizes facts. For instance, The New York team has won the World Series titles the most and hence it always returns that they will win any future World Series. Or when objects are compared, the second one is always heavier. Or that whenever we ask what comes before 10^x, 'something and ninety-nine' is always the answer.</p><p>Google Search on the other hand gives you correct answers whenever possible but it can not formulate your answers to be more aligned to the question. It will retrieve the information that is closest to what you are looking for but it would rarely be nonsensical.</p><p>In other words, GPT3 is just a lossy compression of the data that is not even good at compressing (compression ratio of 2.85) but at the same time has a decent approximate query engine that can parse the input query and formulate an approximately accurate response with grammatical precision. My hypothesis regarding heuristics needs further investigation. If anyone reading this has access to the API and would love to collaborate, please do me a favor.</p></div><footer class="wrapper post__footer"><p class="post__last-updated">This article was updated on February 10, 2021</p><div class="post__share"><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.samagra14.ml%2Fopenai-gpt3-vs-google-the-turing-test.html" class="js-share facebook" rel="nofollow noopener noreferrer"><svg class="icon" aria-hidden="true" focusable="false"><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#facebook"/></svg> <span>Facebook</span> </a><a href="https://twitter.com/share?url=https%3A%2F%2Fwww.samagra14.ml%2Fopenai-gpt3-vs-google-the-turing-test.html&amp;via=samagra_sharma&amp;text=OpenAI%20GPT3%20vs%20Google%3A%20The%20Turing%20Test" class="js-share twitter" rel="nofollow noopener noreferrer"><svg class="icon" aria-hidden="true" focusable="false"><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#twitter"/></svg> <span>Twitter</span> </a><a href="https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fwww.samagra14.ml%2Fopenai-gpt3-vs-google-the-turing-test.html&amp;media=undefined&amp;description=OpenAI%20GPT3%20vs%20Google%3A%20The%20Turing%20Test" class="js-share pinterest" rel="nofollow noopener noreferrer"><svg class="icon" aria-hidden="true" focusable="false"><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#pinterest"/></svg> <span>Pinterest</span> </a><a href="https://mix.com/add?url=https%3A%2F%2Fwww.samagra14.ml%2Fopenai-gpt3-vs-google-the-turing-test.html" class="js-share mix" rel="nofollow noopener noreferrer"><svg class="icon" aria-hidden="true" focusable="false"><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#mix"/></svg> <span>Mix</span> </a><a href="http://www.linkedin.com/shareArticle?url=https%3A%2F%2Fwww.samagra14.ml%2Fopenai-gpt3-vs-google-the-turing-test.html&amp;title=OpenAI%20GPT3%20vs%20Google%3A%20The%20Turing%20Test" class="js-share linkedin" rel="nofollow noopener noreferrer"><svg class="icon" aria-hidden="true" focusable="false"><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#linkedin"/></svg> <span>LinkedIn</span> </a><a href="https://buffer.com/add?text=OpenAI%20GPT3%20vs%20Google%3A%20The%20Turing%20Test&amp;url=https%3A%2F%2Fwww.samagra14.ml%2Fopenai-gpt3-vs-google-the-turing-test.html" class="js-share buffer" rel="nofollow noopener noreferrer"><svg class="icon" aria-hidden="true" focusable="false"><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#buffer"/></svg> <span>Buffer</span> </a><a href="https://api.whatsapp.com/send?text=OpenAI%20GPT3%20vs%20Google%3A%20The%20Turing%20Test https%3A%2F%2Fwww.samagra14.ml%2Fopenai-gpt3-vs-google-the-turing-test.html" class="js-share whatsapp" rel="nofollow noopener noreferrer"><svg class="icon" aria-hidden="true" focusable="false"><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#whatsapp"/></svg> <span>WhatsApp</span></a></div><div class="post__bio bio"><img class="bio__avatar" src="https://www.samagra14.ml/media/website/prof_pic.png" loading="lazy" alt="Samagra Sharma"><div class="bio__info"><h3 class="bio__name"><a href="https://www.samagra14.ml/authors/samagra-sharma/" class="invert" rel="author">Samagra Sharma</a></h3><p>Samagra is an AI Researcher at Adobe Media and Data Science Research Labs. He graduated from IIT Roorkee with a Bachelor&#x27;s in Computer Science and Engineering.</p></div></div></footer></article><nav class="post__nav"><div class="post__nav-inner"><div class="post__nav-prev"><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#arrow-prev"/></svg> <a href="https://www.samagra14.ml/thoughts-on-ai-will-a-bias-free-ai-even-be-human-like.html" class="invert post__nav-link" rel="prev"><span>Previous</span> Thoughts on AI: Will a bias-free AI even be human-like?</a></div><div class="post__nav-next"><a href="https://www.samagra14.ml/incomplete-ideas.html" class="invert post__nav-link" rel="next"><span>Next</span> Incomplete Ideas </a><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#arrow-next"/></svg></div></div></nav><div class="post__comments"><div class="wrapper"><h2 class="h5">Comments</h2><div id="disqus_thread"></div><script>var disqus_config = function () {
                       this.page.url = 'https://www.samagra14.ml/openai-gpt3-vs-google-the-turing-test.html';
               		this.page.identifier = '8';
                   };
               
                   var disqus_loaded = false;
               
                   function publiiLoadDisqus() {
                       if(disqus_loaded) {
                           return false;
                       }
               
                       var top = document.getElementById('disqus_thread').offsetTop;
               
                       if (!disqus_loaded && (window.scrollY || window.pageYOffset) + window.innerHeight > top) {
                           disqus_loaded = true;
               
                           (function () {
                               var d = document, s = d.createElement('script');
                               s.src = 'https://'+'samagrasharma'.trim()+'.disqus.com/embed.js';
                               s.setAttribute('data-timestamp', +new Date());
                               (d.head || d.body).appendChild(s);
                           })();
                       }
                   }
               
                   publiiLoadDisqus();
               
                   window.onscroll = function() {
                       publiiLoadDisqus();
                   };</script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="nofollow noopener noreferrer">comments powered by Disqus.</a></noscript></div></div></main><footer class="footer"><div class="footer__social"><a href="https://www.facebook.com/samagra.sharma" aria-label="Facebook"><svg><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#facebook"/></svg> </a><a href="https://twitter.com/samagra_sharma" aria-label="Twitter"><svg><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#twitter"/></svg> </a><a href="https://www.instagram.com/samagra14/" aria-label="Instagram"><svg><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#instagram"/></svg> </a><a href="https://www.linkedin.com/in/samagra-sharma-4476bb135/" aria-label="LinkedIn"><svg><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#linkedin"/></svg></a></div><div class="footer__copyright"><p>Powered by <a href="https://getpublii.com" target="_blank" rel="nofollow noopener">Publii</a></p></div><button class="footer__bttop js-footer__bttop" aria-label="Back to top"><svg><title>Back to top</title><use xlink:href="https://www.samagra14.ml/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script>window.publiiThemeMenuConfig = {    
        mobileMenuMode: 'sidebar',
        animationSpeed: 300,
        submenuWidth: 'auto',
        doubleClickTime: 500,
        mobileMenuExpandableSubmenus: true, 
        relatedContainerForOverlayMenuSelector: '.top',
   };</script><script defer="defer" src="https://www.samagra14.ml/assets/js/scripts.min.js?v=f4c4d35432d0e17d212f2fae4e0f8247"></script><script>var images = document.querySelectorAll('img[loading]');

        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>